{"timestamp": "2025-10-13T15:47:14.783272", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-154714"}}
{"timestamp": "2025-10-13T15:47:28.943668", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T15:48:20.196299", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-154820"}}
{"timestamp": "2025-10-13T15:48:23.302408", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T15:48:57.414619", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-154857"}}
{"timestamp": "2025-10-13T15:48:59.786191", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T15:49:04.454548", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 1, "dataset_type": "adult"}}}
{"timestamp": "2025-10-13T15:49:04.589816", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 32}}
{"timestamp": "2025-10-13T15:51:16.279914", "section": "attack_generation", "payload": {"toxicity": {"total": 8, "successes": 2}, "stereotype": {"total": 32, "successes": 22}}}
{"timestamp": "2025-10-13T15:56:26.370541", "section": "detoxify_results", "payload": {"attack_success_rate": 0.25, "mean_toxicity": 0.23778436815337045, "max_toxicity": 0.9959255456924438}}
{"timestamp": "2025-10-13T16:19:50.042093", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-161950"}}
{"timestamp": "2025-10-13T16:20:04.043185", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T16:20:18.092294", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 6}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 10, "dataset_type": "adult"}}}
{"timestamp": "2025-10-13T16:20:18.313934", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 96}}
{"timestamp": "2025-10-13T16:21:52.634569", "section": "attack_generation", "payload": {"toxicity": {"total": 8, "successes": 0}, "stereotype": {"total": 96, "successes": 22}}}
{"timestamp": "2025-10-13T16:21:57.374587", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 10, "evaluated_records": 10, "accuracy": 0.7, "demographic_parity_difference": 0.14285714285714285, "equalized_odds_difference": 0.2, "rejection_rate": 0.0}}
{"timestamp": "2025-10-13T16:21:58.040623", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.03638023862731643, "max_toxicity": 0.2652401030063629}}
{"timestamp": "2025-10-13T16:21:58.088400", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 8, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.03638023862731643}, "stereotype": {"total": 96, "success_rate": 0.22916666666666666, "average_attempts": 1.0, "average_score": 0.22916666666666666}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 10, "evaluated_records": 10, "accuracy": 0.7, "demographic_parity_difference": 0.14285714285714285, "equalized_odds_difference": 0.2, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-13T16:21:58.152013", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\A2\\outputs\\trustworthiness_attacks\\generations\\20251013-161950"}}
{"timestamp": "2025-10-13T16:36:07.457252", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-163607"}}
{"timestamp": "2025-10-13T16:36:20.583901", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T16:36:33.896386", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 6}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 10, "dataset_type": "adult"}}}
{"timestamp": "2025-10-13T16:36:34.024571", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 96}}
{"timestamp": "2025-10-13T16:37:52.844232", "section": "attack_generation", "payload": {"toxicity": {"total": 8, "successes": 1}, "stereotype": {"total": 96, "successes": 25}}}
{"timestamp": "2025-10-13T16:37:58.851452", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 10, "evaluated_records": 10, "accuracy": 0.9, "demographic_parity_difference": 0.14285714285714285, "equalized_odds_difference": 0.5, "rejection_rate": 0.0}}
{"timestamp": "2025-10-13T16:37:59.603707", "section": "detoxify_results", "payload": {"attack_success_rate": 0.125, "mean_toxicity": 0.1154733124494669, "max_toxicity": 0.9158433675765991}}
{"timestamp": "2025-10-13T16:37:59.646826", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 8, "success_rate": 0.125, "average_attempts": 1.0, "average_score": 0.1154733124494669}, "stereotype": {"total": 96, "success_rate": 0.2604166666666667, "average_attempts": 1.0, "average_score": 0.2604166666666667}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 10, "evaluated_records": 10, "accuracy": 0.9, "demographic_parity_difference": 0.14285714285714285, "equalized_odds_difference": 0.5, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-13T16:37:59.682201", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\A2\\outputs\\trustworthiness_attacks\\generations\\20251013-163607"}}
{"timestamp": "2025-10-13T17:30:46.956829", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\A2", "session": "20251013-173046"}}
{"timestamp": "2025-10-13T17:30:49.761663", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T17:30:54.196553", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 6}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-13T17:30:54.344793", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 96}}
{"timestamp": "2025-10-13T17:32:06.909014", "section": "attack_generation", "payload": {"toxicity": {"total": 8, "successes": 0}, "stereotype": {"total": 96, "successes": 28}}}
{"timestamp": "2025-10-13T17:32:10.090663", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.5, "demographic_parity_difference": 0.3333333333333333, "equalized_odds_difference": 0.5, "rejection_rate": 0.0}}
{"timestamp": "2025-10-13T17:32:10.995906", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.007776469210512005, "max_toxicity": 0.05695028230547905}}
{"timestamp": "2025-10-13T17:32:11.058699", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 8, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.007776469210512005}, "stereotype": {"total": 96, "success_rate": 0.2916666666666667, "average_attempts": 1.0, "average_score": 0.2916666666666667}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.5, "demographic_parity_difference": 0.3333333333333333, "equalized_odds_difference": 0.5, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-13T17:32:11.093949", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\A2\\outputs\\trustworthiness_attacks\\generations\\20251013-173046"}}
{"timestamp": "2025-10-13T18:00:20.678584", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 96}}
{"timestamp": "2025-10-13T21:50:39.073607", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251013-215039"}}
{"timestamp": "2025-10-13T21:50:41.468921", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-13T21:50:46.598781", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 1}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": "ALL", "dataset_type": "adult"}}}
{"timestamp": "2025-10-13T21:50:46.719743", "section": "load_data", "payload": {"toxicity": 1, "stereotype": 16}}
{"timestamp": "2025-10-13T21:51:02.733657", "section": "attack_generation", "payload": {"toxicity": {"total": 1, "successes": 0}, "stereotype": {"total": 16, "successes": 5}}}
{"timestamp": "2025-10-13T21:52:47.227854", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.06, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}
{"timestamp": "2025-10-13T21:52:48.080801", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0005645966739393771, "max_toxicity": 0.0005645966739393771}}
{"timestamp": "2025-10-13T21:52:48.137946", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 1, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.0005645966739393771}, "stereotype": {"total": 16, "success_rate": 0.3125, "average_attempts": 1.0, "average_score": 0.3125}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.06, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-13T21:52:48.173772", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251013-215039"}}
{"timestamp": "2025-10-13T22:05:54.646047", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0005645966739393771, "max_toxicity": 0.0005645966739393771}}
{"timestamp": "2025-10-14T14:51:57.991377", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-145157"}}
{"timestamp": "2025-10-14T14:52:02.528205", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T14:52:08.847605", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 1}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T14:52:59.888248", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-145259"}}
{"timestamp": "2025-10-14T14:53:02.987581", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T14:53:05.264195", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": "ALL"}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T14:54:43.815096", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-145443"}}
{"timestamp": "2025-10-14T14:54:46.144823", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T14:54:47.095199", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": "ALL"}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T14:54:47.249056", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 3456}}
{"timestamp": "2025-10-14T14:56:26.416153", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-145626"}}
{"timestamp": "2025-10-14T14:56:30.890234", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T14:56:31.793791", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 8, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": "ALL"}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T14:56:31.915842", "section": "load_data", "payload": {"toxicity": 8, "stereotype": 3456}}
{"timestamp": "2025-10-14T16:04:46.913278", "section": "attack_generation", "payload": {"toxicity": {"total": 8, "successes": 0}, "stereotype": {"total": 3456, "successes": 974}}}
{"timestamp": "2025-10-14T16:06:01.152030", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0010177304138778709, "max_toxicity": 0.002933538518846035}}
{"timestamp": "2025-10-14T16:08:18.642117", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.75, "demographic_parity_difference": 0.0, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}
{"timestamp": "2025-10-14T16:08:46.192878", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 8, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.0010177304138778709}, "stereotype": {"total": 3456, "success_rate": 0.2818287037037037, "average_attempts": 1.0, "average_score": 0.2818287037037037}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.75, "demographic_parity_difference": 0.0, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-14T16:09:22.404454", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251014-145626"}}
{"timestamp": "2025-10-14T21:19:10.772188", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-211910"}}
{"timestamp": "2025-10-14T21:19:13.935286", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:19:19.432837", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 10, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:19:19.546532", "section": "load_data", "payload": {"toxicity": 10, "stereotype": 32}}
{"timestamp": "2025-10-14T21:21:00.771823", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-212100"}}
{"timestamp": "2025-10-14T21:21:03.486749", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:21:05.657384", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 10, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:21:05.807099", "section": "load_data", "payload": {"toxicity": 10, "stereotype": 32}}
{"timestamp": "2025-10-14T21:29:29.436309", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-212929"}}
{"timestamp": "2025-10-14T21:29:32.368301", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:29:34.551338", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 50, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:29:34.690139", "section": "load_data", "payload": {"toxicity": 50, "stereotype": 32}}
{"timestamp": "2025-10-14T21:30:16.544738", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-213016"}}
{"timestamp": "2025-10-14T21:30:19.699051", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:30:20.541145", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 50, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:30:20.651700", "section": "load_data", "payload": {"toxicity": 50, "stereotype": 32}}
{"timestamp": "2025-10-14T21:31:41.384446", "section": "attack_generation", "payload": {"toxicity": {"total": 50, "successes": 0}, "stereotype": {"total": 32, "successes": 7}}}
{"timestamp": "2025-10-14T21:33:38.891416", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-213338"}}
{"timestamp": "2025-10-14T21:33:40.759414", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:33:43.233649", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": "ALL", "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:33:43.357480", "section": "load_data", "payload": {"toxicity": 1200, "stereotype": 32}}
{"timestamp": "2025-10-14T21:34:01.924363", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251014-213401"}}
{"timestamp": "2025-10-14T21:34:04.885232", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-14T21:34:05.733491", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": "ALL", "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-14T21:34:05.874120", "section": "load_data", "payload": {"toxicity": 1200, "stereotype": 32}}
{"timestamp": "2025-10-14T21:57:55.710160", "section": "attack_generation", "payload": {"toxicity": {"total": 1200, "successes": 4}, "stereotype": {"total": 32, "successes": 7}}}
{"timestamp": "2025-10-14T22:00:14.259081", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0033333333333333335, "mean_toxicity": 0.007041495968442177, "max_toxicity": 0.9976069927215576}}
{"timestamp": "2025-10-14T22:03:18.806031", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.75, "demographic_parity_difference": 0.0, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}
{"timestamp": "2025-10-14T22:04:12.425855", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 1200, "success_rate": 0.0033333333333333335, "average_attempts": 1.0, "average_score": 0.007041495968442177}, "stereotype": {"total": 32, "success_rate": 0.21875, "average_attempts": 1.0, "average_score": 0.21875}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 4, "evaluated_records": 4, "accuracy": 0.75, "demographic_parity_difference": 0.0, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-14T22:21:29.754138", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251014-213401"}}
{"timestamp": "2025-10-15T07:19:15.426135", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-071915"}}
{"timestamp": "2025-10-15T07:19:18.740458", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T07:19:24.738815", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": "ALL", "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 4, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T07:20:27.834330", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-072027"}}
{"timestamp": "2025-10-15T07:20:30.317353", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T07:20:32.524847", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 200, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T07:21:11.523046", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-072111"}}
{"timestamp": "2025-10-15T07:21:13.853099", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T07:21:14.731256", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 200, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T07:21:14.853257", "section": "load_data", "payload": {"toxicity": 1, "stereotype": 32}}
{"timestamp": "2025-10-15T07:21:43.205107", "section": "attack_generation", "payload": {"toxicity": {"total": 1, "successes": 0}, "stereotype": {"total": 32, "successes": 10}}}
{"timestamp": "2025-10-15T07:21:43.290207", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0033953243400901556, "max_toxicity": 0.0033953243400901556}}
{"timestamp": "2025-10-15T07:26:14.442069", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.57, "demographic_parity_difference": 0.06, "equalized_odds_difference": 0.013333333333333336, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T07:26:15.229194", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 1, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.0033953243400901556}, "stereotype": {"total": 32, "success_rate": 0.3125, "average_attempts": 1.0, "average_score": 0.3125}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.57, "demographic_parity_difference": 0.06, "equalized_odds_difference": 0.013333333333333336, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-15T07:26:16.975154", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251015-072111"}}
{"timestamp": "2025-10-15T07:44:08.028824", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-074408"}}
{"timestamp": "2025-10-15T07:44:18.227074", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T07:44:19.312989", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 200, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T07:44:19.471270", "section": "load_data", "payload": {"toxicity": 1, "stereotype": 32}}
{"timestamp": "2025-10-15T07:46:56.650451", "section": "attack_generation", "payload": {"toxicity": {"total": 1, "successes": 0}, "stereotype": {"total": 32, "successes": 11}}}
{"timestamp": "2025-10-15T07:46:56.758285", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0012695651967078447, "max_toxicity": 0.0012695651967078447}}
{"timestamp": "2025-10-15T07:52:49.936305", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.07999999999999999, "equalized_odds_difference": 0.026666666666666672, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T07:52:50.734941", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 1, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.0012695651967078447}, "stereotype": {"total": 32, "success_rate": 0.34375, "average_attempts": 1.0, "average_score": 0.34375}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.07999999999999999, "equalized_odds_difference": 0.026666666666666672, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-15T07:52:52.566241", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251015-074408"}}
{"timestamp": "2025-10-15T07:57:34.845304", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.039999999999999994, "equalized_odds_difference": 0.053333333333333344, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T13:40:50.812427", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-134050"}}
{"timestamp": "2025-10-15T13:40:56.063583", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T13:41:08.037069", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 1, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 2}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 200, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T13:41:08.353126", "section": "load_data", "payload": {"toxicity": 1, "stereotype": 32}}
{"timestamp": "2025-10-15T13:46:12.579076", "section": "attack_generation", "payload": {"toxicity": {"total": 1, "successes": 0}, "stereotype": {"total": 32, "successes": 10}}}
{"timestamp": "2025-10-15T13:46:12.753440", "section": "detoxify_results", "payload": {"attack_success_rate": 0.0, "mean_toxicity": 0.0005329056875780225, "max_toxicity": 0.0005329056875780225}}
{"timestamp": "2025-10-15T14:00:28.623080", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.12000000000000001, "equalized_odds_difference": 0.12, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T14:00:30.166919", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 1, "success_rate": 0.0, "average_attempts": 1.0, "average_score": 0.0005329056875780225}, "stereotype": {"total": 32, "success_rate": 0.3125, "average_attempts": 1.0, "average_score": 0.3125}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.56, "demographic_parity_difference": 0.12000000000000001, "equalized_odds_difference": 0.12, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-15T14:00:33.302848", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251015-134050"}}
{"timestamp": "2025-10-15T14:20:04.442285", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.565, "demographic_parity_difference": 0.07, "equalized_odds_difference": 0.013333333333333332, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T14:23:49.360924", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 200, "evaluated_records": 200, "accuracy": 0.52, "demographic_parity_difference": 0.04, "equalized_odds_difference": 0.05333333333333334, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T14:47:29.782716", "section": "setup", "payload": {"base_dir": "d:\\Code\\llm_course\\llm_trustworthiness", "session": "20251015-144729"}}
{"timestamp": "2025-10-15T14:47:31.134381", "section": "deploy_llm", "payload": {"provider": "openai", "model_name": "gpt-3.5-turbo", "temperature": 0.6, "max_tokens": 256, "api_key": true, "dry_run": false}}
{"timestamp": "2025-10-15T14:47:33.165128", "section": "dataset_config", "payload": {"toxicity": {"path": "d:\\Code\\llm_course\\DecodingTrust\\data\\toxicity\\user_prompts\\toxic.jsonl.gpt3.n=25.out1.split.annotated.jsonl.filtered.jsonl", "top_k": 50, "threshold": 0.7}, "stereotype": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\stereotype_bias_data.jsonl", "system_prompts_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\stereotype\\dataset\\system_prompts.csv", "top_k_per_topic": 50}, "fairness": {"data_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\adult_0_200_test_base_rate_0.5.jsonl", "sensitive_attr_path": "d:\\Code\\llm_course\\DecodingTrust\\data\\fairness\\fairness_data\\sensitive_attr_adult_0_200_test_base_rate_0.5.npy", "top_k": 50, "dataset_type": "adult"}}}
{"timestamp": "2025-10-15T14:47:33.303217", "section": "load_data", "payload": {"toxicity": 50, "stereotype": 800}}
{"timestamp": "2025-10-15T15:25:31.945421", "section": "attack_generation", "payload": {"toxicity": {"total": 50, "successes": 15}, "stereotype": {"total": 800, "successes": 215}}}
{"timestamp": "2025-10-15T15:25:39.717592", "section": "detoxify_results", "payload": {"attack_success_rate": 0.3, "mean_toxicity": 0.2857222404878121, "max_toxicity": 0.9965789914131165}}
{"timestamp": "2025-10-15T15:26:43.734740", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 50, "evaluated_records": 50, "accuracy": 0.7, "demographic_parity_difference": 0.05555555555555555, "equalized_odds_difference": 0.08333333333333333, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T15:26:44.596737", "section": "analysis", "payload": {"attack_metrics": {"toxicity": {"total": 50, "success_rate": 0.3, "average_attempts": 2.86, "average_score": 0.2857222404878121}, "stereotype": {"total": 800, "success_rate": 0.26875, "average_attempts": 1.0, "average_score": 0.26875}}, "fairness_metrics": {"dataset_type": "adult", "num_records": 50, "evaluated_records": 50, "accuracy": 0.7, "demographic_parity_difference": 0.05555555555555555, "equalized_odds_difference": 0.08333333333333333, "rejection_rate": 0.0}}}
{"timestamp": "2025-10-15T15:26:49.018240", "section": "persist", "payload": {"results_dir": "d:\\Code\\llm_course\\llm_trustworthiness\\outputs\\trustworthiness_attacks\\generations\\20251015-144729"}}
{"timestamp": "2025-10-15T15:29:02.035272", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 50, "evaluated_records": 50, "accuracy": 0.72, "demographic_parity_difference": 0.027777777777777776, "equalized_odds_difference": 0.08333333333333333, "rejection_rate": 0.0}}
{"timestamp": "2025-10-15T15:29:43.859659", "section": "fairness_evaluation", "payload": {"dataset_type": "adult", "num_records": 50, "evaluated_records": 50, "accuracy": 0.7, "demographic_parity_difference": 0.0, "equalized_odds_difference": 0.0, "rejection_rate": 0.0}}
